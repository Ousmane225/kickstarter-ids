{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://172.16.6.174:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.5</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f174ef10dd8>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = SparkSession.builder.getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of lines: 107615\n"
     ]
    }
   ],
   "source": [
    "df_kids = spark.read.parquet('../data/kickstarter.parquet')\n",
    "print(f'Number of lines: {df_kids.count()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- project_id: string (nullable = true)\n",
      " |-- goal: double (nullable = true)\n",
      " |-- final_status: integer (nullable = true)\n",
      " |-- country_clean: string (nullable = true)\n",
      " |-- currency_clean: string (nullable = true)\n",
      " |-- deadline_clean: date (nullable = true)\n",
      " |-- created_at_clean: date (nullable = true)\n",
      " |-- launched_at_clean: date (nullable = true)\n",
      " |-- days_campaign: integer (nullable = true)\n",
      " |-- hours_prepa: double (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_kids.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                text|\n",
      "+--------------------+\n",
      "|where demons danc...|\n",
      "|i want to bring l...|\n",
      "|whole, an art exh...|\n",
      "|make music and me...|\n",
      "|once you know...a...|\n",
      "|modular desktop c...|\n",
      "|rolling freight b...|\n",
      "|\"theodore wants t...|\n",
      "|afterglow radio w...|\n",
      "|the best of betty...|\n",
      "|\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"...|\n",
      "|rockers with love...|\n",
      "|help support - je...|\n",
      "|prepared televisi...|\n",
      "|there it was ther...|\n",
      "|building the open...|\n",
      "|anima - the film....|\n",
      "|\"flatbed honeymoo...|\n",
      "|stuffer the story...|\n",
      "|participate in a ...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_kids.select('text').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----------+-------------+--------------+------------+\n",
      "|days_campaign|hours_prepa|country_clean|currency_clean|final_status|\n",
      "+-------------+-----------+-------------+--------------+------------+\n",
      "|           90|        1.1|           US|           USD|           0|\n",
      "|           29|      41.62|           US|           USD|           1|\n",
      "|           28|       18.7|           US|           USD|           0|\n",
      "|           47|      75.69|           US|           USD|           0|\n",
      "|           45|     457.74|           US|           USD|           0|\n",
      "|           45|     380.94|           US|           USD|           1|\n",
      "|           46|     814.58|           US|           USD|           1|\n",
      "|           61|      58.93|           US|           USD|           0|\n",
      "|           40|       2.16|           US|           USD|           1|\n",
      "|           44|     191.41|           US|           USD|           0|\n",
      "|           30|      43.21|           US|           USD|           0|\n",
      "|           60|     524.22|           US|           USD|           0|\n",
      "|           90|      15.02|           US|           USD|           1|\n",
      "|           15|       0.97|           US|           USD|           1|\n",
      "|           30|       6.46|           US|           USD|           1|\n",
      "|           37|    2015.13|           US|           USD|           1|\n",
      "|           30|     137.33|           US|           USD|           0|\n",
      "|           48|      45.23|           US|           USD|           1|\n",
      "|           85|     838.04|           US|           USD|           1|\n",
      "|           54|       3.47|           US|           USD|           1|\n",
      "+-------------+-----------+-------------+--------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "features = ['days_campaign', 'hours_prepa', 'country_clean', 'currency_clean']\n",
    "label = 'final_status'\n",
    "\n",
    "df = df_kids.select(features + [label])\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_string_indexer(col_name: str) -> StringIndexer:\n",
    "    return StringIndexer().setInputCol(col_name).setOutputCol(f'{col_name}_indexed').setHandleInvalid(\"keep\")\n",
    "\n",
    "def build_one_hot_encoder(col_name: str) -> OneHotEncoder:\n",
    "    return OneHotEncoder().setInputCol(col_name).setOutputCol(f'{col_name}_encoded')\n",
    "\n",
    "categorical_columns = ['days_campaign', 'hours_prepa', 'country_clean', 'currency_clean']\n",
    "\n",
    "indexing_stages = [build_string_indexer(c) for c in categorical_columns]\n",
    "indexed_columns = [s.getOutputCol() for s in indexing_stages]\n",
    "encoding_stages = [build_one_hot_encoder(c) for c in indexed_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_assembler = VectorAssembler()\\\n",
    "    .setInputCols([s.getOutputCol() for s in encoding_stages])\\\n",
    "    .setOutputCol('features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\\\n",
    "    .setMaxIter(3)\\\n",
    "    .setFeaturesCol(vector_assembler.getOutputCol())\\\n",
    "    .setLabelCol('final_status')\n",
    "    \n",
    "model_specs = Pipeline().setStages(indexing_stages + encoding_stages + [vector_assembler] + [lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting model on 86092 lines\n",
      "Evaluating model\n",
      "{'train_auc': 0.9658356041416117, 'test_auc': 0.5431559786851168}\n",
      "Logging to mlflow\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.tuning import TrainValidationSplit\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "import mlflow\n",
    "from mlflow.spark import log_model\n",
    "\n",
    "df_train, df_test = df.randomSplit([0.8, 0.2], seed=12345)\n",
    "df_train = df_train.cache()\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator()\\\n",
    "    .setMetricName('areaUnderROC')\\\n",
    "    .setRawPredictionCol('rawPrediction')\\\n",
    "    .setLabelCol('final_status')\n",
    "\n",
    "mlflow_tracking_ui = 'http://35.246.84.226'\n",
    "mlflow_experiment_name = 'kickstarter'\n",
    "\n",
    "mlflow.set_tracking_uri(mlflow_tracking_ui)\n",
    "mlflow.set_experiment(experiment_name=mlflow_experiment_name)\n",
    "\n",
    "with mlflow.start_run() as active_run:\n",
    "    print(f'Fitting model on {df_train.count()} lines')\n",
    "\n",
    "    model = model_specs.fit(df_train)\n",
    "\n",
    "    print('Evaluating model')\n",
    "    train_metrics = evaluator.evaluate(model.transform(df_train))\n",
    "    metrics = {'train_auc': train_metrics}\n",
    "\n",
    "    test_metrics = evaluator.evaluate(model.transform(df_test))\n",
    "    metrics.update({'test_auc': test_metrics})\n",
    "    print(metrics)\n",
    "    \n",
    "    print('Logging to mlflow')\n",
    "    mlflow.log_params({'model_class': 'logistic regression', 'lr_max_iter': lr.getMaxIter()})\n",
    "    mlflow.log_metrics(metrics)\n",
    "    log_model(model, 'model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
